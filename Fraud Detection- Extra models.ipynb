{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import ensemble\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load credit card transaction dataset\n",
    "df = pd.read_csv(\"card_transdata(1).csv\")\n",
    "\n",
    "## Store the data as X and y where X stores input features and y stores fraud indication\n",
    "X = df.drop(\"fraud\", axis=1).values\n",
    "Y = df[\"fraud\"].values\n",
    "\n",
    "# seperate out 20% of data as the validation set to ensure no overfitting\n",
    "X_set,X_valid, Y_set, Y_valid = train_test_split(X, Y, test_size=0.2, random_state=30)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_set, Y_set, test_size=0.2, random_state=30)\n",
    "\n",
    "## Resample the training set to balance the classes\n",
    "oversampler = SMOTE(random_state=30)\n",
    "X_train_resampled, Y_train_resampled = oversampler.fit_resample(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data:\n",
      "Accuracy: 0.9999875\n",
      "Precision: 1.0\n",
      "Recall: 0.9998573669947226\n",
      "F1 score: 0.999928678410955\n",
      "Flagged Fraud       0      1\n",
      "Actual Fraud                \n",
      "0              145978      0\n",
      "1                   2  14020\n",
      "Validation Data:\n",
      "Validation\n",
      "Accuracy: 0.999985\n",
      "Precision: 1.0\n",
      "Recall: 0.9998285028297033\n",
      "F1 score: 0.9999142440614013\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc = rfc.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "y_pred_rfc = rfc.predict(X_test)\n",
    "\n",
    "\n",
    "print('Test Data:')\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred_rfc))\n",
    "print(\"Precision:\", metrics.precision_score(Y_test, y_pred_rfc))\n",
    "print(\"Recall:\", metrics.recall_score(Y_test, y_pred_rfc))\n",
    "print(\"F1 score:\", metrics.f1_score(Y_test, y_pred_rfc))\n",
    "print(pd.crosstab(Y_test, y_pred_rfc, rownames=[\"Actual Fraud\"], colnames=[\"Flagged Fraud\"]))\n",
    "\n",
    "y_pred_rfc_valid = rfc.predict(X_valid)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(\"Validation\")\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_valid, y_pred_rfc_valid))\n",
    "print(\"Precision:\", metrics.precision_score(Y_valid, y_pred_rfc_valid))\n",
    "print(\"Recall:\", metrics.recall_score(Y_valid, y_pred_rfc_valid))\n",
    "print(\"F1 score:\", metrics.f1_score(Y_valid, y_pred_rfc_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36507/36507 [==============================] - 60s 2ms/step - loss: 0.0562 - precision_1: 0.9758 - recall_1: 0.9890 - auc_1: 0.9975 - accuracy: 0.9822\n",
      "Epoch 2/10\n",
      "36507/36507 [==============================] - 58s 2ms/step - loss: 0.0204 - precision_1: 0.9913 - recall_1: 0.9953 - auc_1: 0.9994 - accuracy: 0.9933\n",
      "Epoch 3/10\n",
      "36507/36507 [==============================] - 58s 2ms/step - loss: 0.0165 - precision_1: 0.9927 - recall_1: 0.9962 - auc_1: 0.9996 - accuracy: 0.9944\n",
      "Epoch 4/10\n",
      "36507/36507 [==============================] - 57s 2ms/step - loss: 0.0148 - precision_1: 0.9935 - recall_1: 0.9965 - auc_1: 0.9996 - accuracy: 0.9950\n",
      "Epoch 5/10\n",
      "36507/36507 [==============================] - 57s 2ms/step - loss: 0.0136 - precision_1: 0.9940 - recall_1: 0.9969 - auc_1: 0.9997 - accuracy: 0.9954\n",
      "Epoch 6/10\n",
      "36507/36507 [==============================] - 58s 2ms/step - loss: 0.0127 - precision_1: 0.9945 - recall_1: 0.9971 - auc_1: 0.9997 - accuracy: 0.9958\n",
      "Epoch 7/10\n",
      "36507/36507 [==============================] - 62s 2ms/step - loss: 0.0117 - precision_1: 0.9950 - recall_1: 0.9972 - auc_1: 0.9997 - accuracy: 0.9961\n",
      "Epoch 8/10\n",
      "36507/36507 [==============================] - 62s 2ms/step - loss: 0.0109 - precision_1: 0.9951 - recall_1: 0.9974 - auc_1: 0.9998 - accuracy: 0.9962\n",
      "Epoch 9/10\n",
      "36507/36507 [==============================] - 65s 2ms/step - loss: 0.0105 - precision_1: 0.9955 - recall_1: 0.9976 - auc_1: 0.9998 - accuracy: 0.9965\n",
      "Epoch 10/10\n",
      "36507/36507 [==============================] - 60s 2ms/step - loss: 0.0101 - precision_1: 0.9956 - recall_1: 0.9976 - auc_1: 0.9998 - accuracy: 0.9966\n",
      "5000/5000 [==============================] - 5s 1ms/step\n",
      "Test Data:\n",
      "Accuracy: 0.9962\n",
      "Precision: 0.9588806787082649\n",
      "Recall: 0.999500784481529\n",
      "F1 score: 0.9787694671415602\n",
      "6250/6250 [==============================] - 7s 1ms/step\n",
      "Test Data:\n",
      "Accuracy: 0.996175\n",
      "Precision: 0.9586532134239965\n",
      "Recall: 0.9993711770422454\n",
      "F1 score: 0.9785888214055808\n"
     ]
    }
   ],
   "source": [
    "## Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='relu', input_dim=X.shape[1]))\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "## Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "              metrics=[Precision(), Recall(), AUC(), 'accuracy'])\n",
    "\n",
    "## Train the model\n",
    "model.fit(X_train_resampled, Y_train_resampled, epochs=10, batch_size=32)\n",
    "\n",
    "## Make predictions on the test inputs\n",
    "y_pred_nn = model.predict(X_test)\n",
    "y_pred_nn = (y_pred_nn > 0.5).astype(int).reshape(-1) # Convert probabilities to binary predictions\n",
    "\n",
    "## Evaluate using the following performance metrics\n",
    "print(\"Test Data:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(Y_test, y_pred_nn))\n",
    "print(\"Precision:\", metrics.precision_score(Y_test, y_pred_nn))\n",
    "print(\"Recall:\", metrics.recall_score(Y_test, y_pred_nn))\n",
    "print(\"F1 score:\", metrics.f1_score(Y_test, y_pred_nn))\n",
    "\n",
    "## Make predictions on the test inputs\n",
    "y_pred_nn_v = model.predict(X_valid)\n",
    "y_pred_nn_v = (y_pred_nn_v > 0.5).astype(int).reshape(-1) # Convert probabilities to binary predictions\n",
    "\n",
    "## Evaluate using the following performance metrics\n",
    "print(\"Validation Data:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(Y_valid, y_pred_nn_v))\n",
    "print(\"Precision:\", metrics.precision_score(Y_valid, y_pred_nn_v))\n",
    "print(\"Recall:\", metrics.recall_score(Y_valid, y_pred_nn_v))\n",
    "print(\"F1 score:\", metrics.f1_score(Y_valid, y_pred_nn_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data:\n",
      "Accuracy: 0.93285\n",
      "Precision: 0.5705917822379188\n",
      "Recall: 0.944801026957638\n",
      "F1 score: 0.7114930182599355\n",
      "Validation Data:\n",
      "Accuracy: 0.934225\n",
      "Precision: 0.5755328040117008\n",
      "Recall: 0.9447779111644657\n",
      "F1 score: 0.7153151983379861\n"
     ]
    }
   ],
   "source": [
    "# Create logistic regression classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train_resampled, Y_train_resampled)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "Y_pred = clf.predict(X_test)\n",
    "                     \n",
    "# Evaluate the performance of the model\n",
    "print('Test Data:')\n",
    "print(\"Accuracy:\", metrics.accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(Y_test, Y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(Y_test, Y_pred))\n",
    "print(\"F1 score:\", metrics.f1_score(Y_test, Y_pred))\n",
    "\n",
    "# Make predictions on the testing data\n",
    "Y_pred_v = clf.predict(X_valid)\n",
    "                     \n",
    "# Evaluate the performance of the model\n",
    "print('Validation Data:')\n",
    "print(\"Accuracy:\", metrics.accuracy_score(Y_valid, Y_pred_v))\n",
    "print(\"Precision:\", metrics.precision_score(Y_valid, Y_pred_v))\n",
    "print(\"Recall:\", metrics.recall_score(Y_valid, Y_pred_v))\n",
    "print(\"F1 score:\", metrics.f1_score(Y_valid, Y_pred_v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
